<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
        "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
  <title>An Gramad&oacute;ir : Other Languages</title>
  <meta http-equiv="Content-Language" content="en">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="description" content="An Gramad&oacute;ir porting page">
  <meta name="keywords" content="grammar checking, Gaeilge, Irish language">
  <meta name="author" content="Kevin P. Scannell">
  <link rel="stylesheet" href="../kps.css" type="text/css">
</head>

<body>
<div class="content">
<h1>An Gramad&oacute;ir:<br>
Porting to other languages</h1>

<hr>
<h2>Introduction</h2>
<p>
I would be excited to help port this software
for use with languages other than Irish.  Getting 
something simple up and running should be easy,
even if your language lacks some of the basic tools for
doing natural language processing.
</p>

<p>
Caveat Emptor: <i lang="ga">An Gramad&oacute;ir</i> finds errors
by first marking up the input text with grammatical information
(ranging from simple part-of-speech tags to full phrase structure)
and then performing 
pattern-matching on the marked up text.   In other words, it
is "rule-based", but without the limitations of a trivial
pattern-matching approach like the one used by the
venerable
<a href="http://www.gnu.org/software/diction/diction.html">GNU "diction"</a>
package.
The complexity of
the errors that can be trapped and reported is limited
only by the sophistication of the markup that is added.
For Irish and the other Celtic languages,
relatively little markup is required because many of the common 
errors made in writing involve misuse of the
<a href="http://www.fiosfeasa.com/bearla/language/claochlo.htm">initial mutations</a>
which are determined almost entirely by local context
(usually, just the preceding word).  Finding errors reliably in languages
like English (or languages with free word order) will require at least
a shallow parse of the input text.
</p>

<p>
In the instructions below, I will use "xx" for
the two-letter ISO-639-1 code for your language.
</p>

<hr>
<h2>Using the Language Pack</h2>
<p>
The first thing you should do if you're interested in 
porting <i lang="ga">An Gramadóir</i> is
<a href="http://borel.slu.edu/">Contact me</a></b>.
Assuming your language is one of the 150+ languages
for which my
<a href="http://borel.slu.edu/crubadan/stadas.html">web crawler</a>
is running, I will create a new language pack for you using
this data.  If you don't have a clean word list there will be
some preliminary work involved in constructing one.
</p>

<p>
If you have a <a href="http://sourceforge.net/">sourceforge</a> 
account, send me your user name and I will add you as a 
developer to the
<a href="http://sourceforge.net/projects/gramadoir/">gramadoir project</a>.
If not, it is easy to
<a href="http://sourceforge.net/account/newuser_emailverify.php">register for an account</a>.
This is required in order to have write access to the project
<a href="http://sourceforge.net/cvs/?group_id=114958">CVS repository</a>.
</p>

<p>
Next, <a href="sios.html">download</a> the latest version of
the developers' pack, extract, and configure it:
</p>

<pre>
$ gunzip gramadoir-x.x.tar.gz
$ tar xvf gramadoir-x.x.tar
$ cd gramadoir-x.x
$ ./configure
</pre>

<p>
This creates a <i>Makefile</i> but at this point there is nothing 
to make and nothing to install.   The developers' pack just
contains the scripts used in converting the language pack files
into an installable Perl module.
</p>

<p>
The next step is to checkout the language pack from CVS.
The sourceforge site has some excellent documentation on
<a href="http://sourceforge.net/docman/display_doc.php?docid=768&group_id=1">using CVS as a developer</a> and an overview document for anyone
<a href="http://sourceforge.net/docman/display_doc.php?docid=14033&group_id=1">new to CVS</a>.
Here is the command (substituting your
sourceforge account name for "username" and your language code for 
"xx"):
</p>

<pre>
$ cvs -d:ext:username@cvs.sf.net:/cvsroot/gramadoir checkout xx
cvs checkout: Updating xx
U xx/3grams-xx.txt
U xx/COPYING
U xx/Changes
U xx/README
U xx/aonchiall-xx.in
U xx/comhshuite-xx.in
...
</pre>

<p>Then run "configure" in this directory to create a Makefile:</p>

<pre>
$ cd xx
$ ./configure
</pre>

<p>
Now anytime you want to create or update the <i>Lingua::XX::Gramadoir</i>
Perl module, you just run "make".  This will generate all
of the necessary files in the subdirectory <i>Lingua-XX-Gramadoir</i>.
You can build, test, and install the module
<a href="http://cpan.uwinnipeg.ca/htdocs/ExtUtils-MakeMaker/ExtUtils/MakeMaker.html#default_makefile_behaviour">in the usual way</a>:
<pre>
$ cd Lingua-XX-Gramadoir
$ perl Makefile.PL
$ make
$ make test
$ make install
</pre>

<p>
Of course, until you actually add some real grammatical rules 
to the language pack input files, the Perl module will
function as a simple spell checker only.   Next I'll describe
the syntax of the input files and some tricks for building them
quickly.
</p>

<hr>
<h2>A tour of the language pack</h2>
<p>
<b>1. Files you don't need to mess with</b>. 
The statistics in <i>3grams-xx.txt</i> and <i>freq-xx.txt</i>
are generated by my web crawler and don't need to be edited. 
Periodically I can provide updates to these files if the 
web corpora grow substantially.   The <i>README</i> and 
<i>COPYING</i> files only need to be changed if you prefer
a license other than the <a href="http://www.gnu.org/licenses/gpl.html">GPL</a>.
You only need to worry about the <i>Changes</i> file before
a release; this gets copied into the top-level directory
of the Perl module.
<i>configure</i> and <i>triail.xml</i> should not be edited at all.
</p>

<p>
<b>2. pos-xx.txt</b>.
Part-of-speech markup is added to input texts as 
XML tags; you'll need to choose these tags first. 
The default is to do no part-of-speech tagging at all
and markup all words with "&lt;U&gt;" (unknown).
If you just want a fancy spell checker this is sufficient.
Otherwise you can place your tags
(e.g. &lt;N&gt;, &lt;V&gt;, &lt;N plural="y"&gt;, etc.)
in <i>pos-xx.txt</i>
and assign a numerical code to each (used internally).
There are a couple of mild restrictions:
<ul>
<li>The numerical codes must lie between 0 and 255, excluding 
the values 0 and 10 (used as file delimiters).
<li>Code 127 has a special meaning across all languages: it is
used to markup words which are correct but are very rare or
might hide common misspellings.   A good example in Irish
is <i lang="ga">brúitíneach</i> which means "a small fat person"
and does not appear in my corpus of over 20 million words
except as a misspelling of <i lang="ga">bruitíneach</i> ("the measles").
<li>The XML tags must be ASCII capital letters, excluding "B",
"E", "F", "X", "Y", and "Z" (which are all tags added to the XML stream
by <i lang="ga">An Gramadóir</i> while checking grammar).  This leaves
20 possible tags, which should be more than enough in light of the
fact that you can refine the semantics of your tags by adding
XML attributes where appropriate.
</ul>
</p>

<p>
<b>3. lexicon-xx.bs and lexicon-xx.txt</b>.
These files contain the main database of recognized words.
The first of these is the compressed version that comes in the tarball,
the latter is the uncompressed version that you should use for
editing, adding words, part-of-speech tags, etc.
If you don't see <i>lexicon-xx.txt</i> you can 
recreate it using:
<pre>
$ make lexicon-xx.txt
</pre>
Conversely, if you ever do a "make dist", the compressed version will
be updated correctly, taking into account any additions or changes
made to <i>lexicon-xx.txt</i>.
The file <i>lexicon-xx.txt</i> contains one word per line followed by
whitespace and one of
the numerical grammatical codes from <i>pos-xx.txt</i>; e.g.:
<pre>
dipper 31
dire 36
direct 33
direct 36
direct 37
directed 36
direction 31
directional 36
directions 32
</pre>
Initially the grammatical codes are all set to "1" (&lt;U&gt;)
as a placeholder.
</p>

<p>
<b>4. eile-xx.bs and earraidi-xx.bs</b>.
The file <i>eile-xx.bs</i> is a "replacement" file which contains on 
each line a non-standard or dialect spelling of a legitimate word 
followed by a suggested replacement.   The file <i>earraidi-xx.bs</i>
is the same, but should be used for true misspellings.
The only difference is how the replacements are reported to
the end-user.
I built the file 
<i>eile-en.bs</i> in the English language pack by collating the
specifically American and British word lists that are distributed with
<i>ispell</i>.  The Irish file <i>eile-ga.bs</i> is a by-product of
my work on dialect support for 
<a href="http://borel.slu.edu/ispell/">Irish language spell checkers</a>.
The replacement "word" is allowed to contain spaces, e.g. 
<pre>
spellchecker spell checker
</pre>
</p>

<p>
<b>5. morph-xx.txt and nocombo-xx.txt</b>.
This file encodes the morphological rules for your language;
it is structured as a sequence of substitutions,
one per line, using Perl regular expression syntax,
with fields separated by whitespace. 
When an unknown word is encountered, these replacements
are applied recursively (depth first) until a match is
found.  
The first field contains the pattern to be replaced,
the second field is the replacement (backreferences allowed,
which moves us beyond the usual realm of finite state 
morphology), and the third field is a code indicating the
"violence level" the change represents.   Level -1 means
that no message should be reported if the rule is applied and
the modified word is found (as in the default 
rule which turn uppercase words into lowercase).
Level 0 means that a message is given which just alerts the
user that the surface form was not found in the database but
that the modified version was.  
Level 1 indicates that the rule applies only to non-standard
or variant
forms and will be reported as such (e.g. for American English you could
define a level 1 rule that changes "^anaesth" to "anesth", 
or globally changes "centre" to "center", etc.)
Level 2 indicates that the rule applies only when the surface
form is truly incorrect in some way.  
</p>
<p>
False positives can be avoided by placing 
words that are not morphologically productive
in the file <i>nocombo-xx.txt</i>.
</p>

<p>
<b>6. comhshuite-xx.in</b>.
Each line of this file contains a "set phrase" that you would like
to be marked up as a single unit.  See the description of this file on the
<a href="cuidiu.html">Contributing</a> page.
</p>
<p>

<p>
<b>7. aonchiall-xx.in</b>.
These are the rules for disambiguation.
See the description of this file on the <a href="cuidiu.html">Contributing</a>
page.  This, and the other input files, also require the macros stored
in <i>macra-xx.meta.pl</i>.
</p>
<p>
After you have a first version working, you can use
<i lang="ga">An Gramadóir</i> itself to help find rules for 
<i>aonchiall-xx.in</i>.   I've implemented the algorithm from 
Eric Brill's paper on unsupervised learning of disambiguation rules
so that the output is suitable for use in <i>aonchiall-xx.in</i>
(and so that the highest-scoring rules come first).  Run it as follows:
<pre>
% cat big.txt | gramdev-xx.pl --brill &gt; rules.txt
</pre>
</p>

<p>
<b>8. unigram-xx.pre and unigram-xx.txt</b>.  
The file <i>unigram-xx.txt</i>
consists of a list of the legal XML part-of-speech tags for your language
sorted in order of frequency highest to lowest.   The disambiguation
module uses this as a "last resort" tagging method.
Sometimes it helps in disambiguation to "lump together" 
several tags (e.g. by stripping attributes that have 
no use in grammar checking).   These can be achieved by
placing appropriate substitutions in <i>unigram-xx.pre</i>.
</p>
<p>
If you actually have some part of speech markup, then after things
are up and running you can create the second of these files using:
<pre>
% cat big.txt | gramdev-xx.pl --minic &gt; unigram-xx.txt
</pre>
</p>

<p>
<b>9. rialacha-xx.in and eisceacht-xx.in</b>.  
These are the grammatical rules and exceptions.
Again see the <a href="cuidiu.html">Contributing</a> page for information
on how to create these files.
The two default rules report unrecognized words and
"rare" words marked up with grammatical code 127.
</p>

<p>
<b>10. giorr-xx.pre and giorr-xx.txt</b>.
The default language pack uses statistical methods to extract
likely abbreviations from a text corpus (i.e. words that appear almost
exclusively followed by a period ".").
You'll find these in <i>giorr-xx.txt</i>.
You may also want to uncomment the lines in 
<i>giorr-xx.pre</i> so that one letter abbreviations
are escaped properly.
Any other unusual conventions for ends of sentences should
get encoded here.
</p>


<hr>
<em>© Cóipcheart/Copyright 2003, 2004 Kevin P. Scannell</em><br><br>
</ul>
</div>
<div class="navigation">
<a href = "index.html">Home</a><br>
<a href = "sios.html">Download</a><br>
<a href = "cuidiu.html">Contributing</a><br>
Languages<br>
<a href = "stair.html">History</a><br>
<a href = "sampla.html">Sampler</a><br>
<a href = "foirm.html">Web Interface</a><br>
<a href = "eagar.html">Editors</a><br>
<a href = "/nlp.html">Projects</a><br>
<p class="centered">
<img src="gram.jpg" alt="dictionary excerpt" height="160" width="125">
</p>
</div>
</body>
</html>

<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
        "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
  <title>An Gramad&oacute;ir : Other Languages</title>
  <meta http-equiv="Content-Language" content="en">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="description" content="An Gramad&oacute;ir porting page">
  <meta name="keywords" content="grammar checking, Gaeilge, Irish language">
  <meta name="author" content="Kevin P. Scannell">
  <link rel="stylesheet" href="../kps.css" type="text/css">
</head>

<body>
<div class="content">
<h1>An Gramad&oacute;ir:<br>
Porting to other languages</h1>

<hr>
<h2>Introduction</h2>
<p>
I would be excited to help port this software
for use with languages other than Irish.  Getting 
something simple up and running should be easy,
even if your language lacks some of the basic tools for
doing natural language processing.
</p>

<p>
Caveat Emptor: <i lang="ga">An Gramad&oacute;ir</i> finds errors
by first marking up the input text with grammatical information
(ranging from simple part-of-speech tags to full phrase structure)
and then performing 
pattern-matching on the marked up text.   The complexity of
the errors that can be trapped and reported is therefore limited
only by the sophistication of the markup that is added.
For Irish and the other Celtic languages,
relatively little markup is required because many of the common 
errors made in writing involve misuse of the initial mutations
which are determined almost entirely by local context
(usually, just the preceding word).  Finding errors reliably in languages
like English (or languages with free word order) will require at least
a shallow parse of the input text.
</p>

<p>
In the instructions below, I will use "xx" for
the two-letter ISO-639-1 code for your language.
</p>

<hr>
<h2>Things to do</h2>
<p>
<b>1. <a href="http://borel.slu.edu/">Contact me</a></b>.
Assuming your language is one of the 150+ languages
for which my <a href="http://borel.slu.edu/crubadan/stadas.html">web crawler</a>
is running, I will create a new language pack for you using
this data.  If you don't have a clean word list there will be
some preliminary work involved in constructing one.

<p>
<b>2. Design a tag set</b>.
Part-of-speech markup is added to input texts as 
XML tags; you'll need to choose these tags first. 
The default is to do no part-of-speech tagging at all
and markup all words with "&lt;U&gt;" (unknown).
If you just want a fancy spellchecker this is sufficient.
Otherwise you can place your tags
(e.g. &lt;N&gt;, &lt;V&gt;, &lt;N plural="y"&gt;, etc.)
in <i>pos-xx.txt</i>
and assign a numerical to each (used internally).
There are a couple of mild restrictions:
<ul>
<li>The numerical codes must lie between 0 and 255, excluding 
the values 0 and 10 (used as file delimiters).
<li>Code 127 has a special meaning across all languages: it is
used to markup words which are correct but are very rare or
might hide common misspellings.   A good example in Irish
is <i lang="ga">brúitíneach</i> which means "a small fat person"
and does not appear in my corpus of over 20 million words
except as a misspelling of <i lang="ga">bruitíneach</i> ("the measles").
<li>The XML tags must be ASCII capital letters, excluding "B",
"E", "F", "X", "Y", and "Z" (which are all tags added to the XML stream
by <i lang="ga">An Gramadóir</i> while checking grammar).  This leaves
20 possible tags, which should be more than enough in light of the
fact that you can refine the semantics of your tags by adding
XML attributes where appropriate.
</ul>
</p>

<p>
<b>3. Build lexicon-xx.txt</b>.
This is the main database of recognized words.
This file contains one word per line followed by whitespace and one of
the numerical grammatical codes from <i>pos-xx.txt</i>; e.g.:
<pre>
dipper 31
dire 36
direct 33
direct 36
direct 37
directed 36
direction 31
directional 36
directions 32
</pre>
Initially the grammatical codes are all set to "1" (&lt;U&gt;)
as a placeholder.
</p>

<p>
<b>4. Build eile-xx.bs and earraidi-xx.bs</b>.
The file <i>eile-xx.bs</i> is a "replacement" file which contains on 
each line a non-standard or dialect spelling of a legitimate word 
followed by a suggested replacement.   The file <i>earraidi-xx.bs</i>
is the same, but should be used for true misspellings.
The only difference is how the replacements are reported to
the end-user.
I built the file 
<i>eile-en.bs</i> in the English language pack by collating the
specifically American and British word lists that are distributed with
<i>ispell</i>.  The Irish file <i>eile-ga.bs</i> is a by-product of
my work on dialect support for 
<a href="http://borel.slu.edu/ispell/">Irish language spellcheckers</a>.
</p>

<p>
<b>5. Encode morphological rules in morph-xx.txt</b>.
This file is structured as a sequence of substitutions,
one per line, using Perl regular expression syntax,
with fields separated by whitespace. 
When an unknown word is encountered, these replacements
are applied recursively (depth first) until a match is
found.  
The first field contains the pattern to be replaced,
the second field is the replacement (backreferences allowed,
which moves us beyond the usual realm of finite state 
morphology), and the third field is a code indicating the
"violence level" the change represents.   Level -1 means
that no message should be reported if the rule is applied and
the modified word is found (as in the default 
rule which turn uppercase words into lowercase).
Level 0 means that a message is given which just alerts the
user that the surface form was not found in the database but
that the modified version was.  
Level 1 indicates that the rule applies only to non-standard
or variant
forms and will be reported as such (e.g. for American English you could
define a level 1 rule that changes "^anaesth" to "anesth", 
or globally changes "centre" to "center", etc.)
Level 2 indicates that the rule applies only when the surface
form is truly incorrect in some way.  
</p>
<p>
False positives can be avoided by placing 
words that are not morphologically productive
in the file <i>nocombo-gd.txt</i>.
</p>

<p>
<b>6. Write comhshuite-xx.in</b>.
Each line of this file contains a "set phrase" that you would like
to be marked up as a single unit.  See the description of this file on the
<a href="cuidiu.html">Contributing</a> page.
</p>
<p>

<p>
<b>7. Write <i>aonchiall-xx.in</i></b>.  These are the rules for disambiguation.
See the description of this file on the <a href="cuidiu.html">Contributing</a>
page.  This, and the other input files, also require the macros stored
in <i>macra-xx.meta.pl</i>.
</p>
<p>
After you have a first version working, you can use
<i lang="ga">An Gramadóir</i> itself to help find rules for 
<i>aonchiall-xx.in</i>.   I've implemented the algorithm from 
Eric Brill's paper on unsupervised learning of disambiguation rules
so that the output is suitable for use in <i>aonchiall-xx.in</i>
(and so that the highest-scoring rules come first).  Run it as follows:
<pre>
% cat bigtextfile | 
  gr --teanga=xx --brill --iomlan &gt;
  rule.candidates
</pre>
</p>

<p>
<b>8. Write <i>unigram-xx.*</i></b>.  
The file <i>unigram-xx.txt</i>
consists of a list of the legal XML part-of-speech tags for your language
(as determined in step three above),
sorted in order of frequency highest to lowest.   The disambiguation
module uses this as a "last resort" tagging method.
</p>
<p>
If you actually have some part of speech markup, then after things
are up and running you can create this file using:
<pre>
% gr --minic bigtextfile &gt; unigram-xx.txt
</pre>
</p>

<p>
<b>9. Write <i>rialacha-xx.in</i> and <i>eisceacht-xx.in</i></b>.  
These are the grammatical rules and exceptions.
Again see the <a href="cuidiu.html">Contributing</a> page for information
on how to create these files.
The two default rules report unrecognized words and
"rare" words marked up with grammatical code 127.
</p>

<p>
<b>10. Deal with abbreviations</b>.
The default language pack uses statistical methods to extract
likely abbreviations from a text corpus (i.e. words that appear almost
exclusively followed by a period ".").
You'll find these in <i>giorr-xx.txt</i>.
You may also want to uncomment the lines in 
<i>giorr-xx.pre</i> so that one letter abbreviations
are escaped properly.
Any other unusual conventions for ends of sentences should
get encoded here.
</p>

<p>
<b>11. Localize message strings</b>.
Technically this is part of porting the user interface, not
porting the grammar checker.  I'm guessing however that you'll want to
see the output in the same language as
the documents that are being
checked.   
You can find out more from our page at the 
<a href="http://www2.iro.umontreal.ca/~gnutra/registry.cgi?domain=gramadoir">GNU Translation Project</a>.
</p>

<hr>
<em>© Cóipcheart/Copyright 2003, 2004 Kevin P. Scannell</em><br><br>
</ul>
</div>
<div class="navigation">
<a href = "index.html">Home</a><br>
<a href = "sios.html">Download</a><br>
<a href = "cuidiu.html">Contributing</a><br>
Languages<br>
<a href = "stair.html">History</a><br>
<a href = "sampla.html">Sampler</a><br>
<a href = "foirm.html">Web Interface</a><br>
<a href = "eagar.html">Editors</a><br>
<a href = "/nlp.html">Projects</a><br>
<p class="centered">
<img src="gram.jpg" alt="dictionary excerpt" height="160" width="125">
</p>
</div>
</body>
</html>
